{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a68cc25",
   "metadata": {
    "papermill": {
     "duration": 0.00902,
     "end_time": "2025-09-30T10:42:42.410755",
     "exception": false,
     "start_time": "2025-09-30T10:42:42.401735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a65fc5e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:42:42.428549Z",
     "iopub.status.busy": "2025-09-30T10:42:42.428066Z",
     "iopub.status.idle": "2025-09-30T10:46:08.418617Z",
     "shell.execute_reply": "2025-09-30T10:46:08.417666Z"
    },
    "papermill": {
     "duration": 206.009277,
     "end_time": "2025-09-30T10:46:08.427716",
     "exception": false,
     "start_time": "2025-09-30T10:42:42.418439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datensätze: (786, 10), Klassenverteilung: [  0 698  88]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Pfad zur Datei\n",
    "file_path = ['/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S14/S14.pkl',\n",
    "             '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S13/S13.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S10/S10.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S5/S5.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S7/S7.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S9/S9.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S15/S15.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S2/S2.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S6/S6.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S3/S3.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S4/S4.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S16/S16.pkl',\n",
    "            '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S17/S17.pkl'\n",
    "            ]\n",
    "\n",
    "features = []\n",
    "window_labels = []\n",
    "\n",
    "for file in file_path:\n",
    "# Laden\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pd.read_pickle(f)\n",
    "    \n",
    "    # Zugriff auf Wrist-Daten\n",
    "    wrist = data['signal']['wrist']\n",
    "    eda = wrist['EDA']      # shape (n_samples, 1)\n",
    "    temp = wrist['TEMP']    # shape (n_samples, 1)\n",
    "    acc = wrist['ACC']      # shape (n_samples, 3)\n",
    "    \n",
    "    # Label (ursprünglich 700 Hz, z. B. 3.8 Mio lang)\n",
    "    labels = data['label']\n",
    "    \n",
    "    # Resampling der Labels auf Länge von EDA (64 Hz)\n",
    "    labels_resampled = resample(labels.astype(float), len(eda))\n",
    "    labels_resampled = np.round(labels_resampled).astype(int)\n",
    "    \n",
    "    # Features kombinieren (z. B. EDA, TEMP, ACC)\n",
    "    from scipy.signal import resample\n",
    "    \n",
    "    # Resample ACC auf Länge von EDA (z. B. 22192 Zeilen)\n",
    "    acc_resampled = resample(acc, len(eda))\n",
    "    \n",
    "    X_raw = np.hstack([eda, temp, acc_resampled])  # shape: (n_samples, 6)\n",
    "\n",
    "    X_raw\n",
    "    \n",
    "    # Sliding Window-Feature-Bildung (z. B. 60s bei 64 Hz = 384 Samples)\n",
    "    window_size = 384  # 60s Fenster\n",
    "    step_size = 384    # ohne Überschneidung\n",
    "\n",
    "    \n",
    "    for start in range(0, len(X_raw) - window_size, step_size):\n",
    "        end = start + window_size\n",
    "        window = X_raw[start:end]\n",
    "        label_window = labels_resampled[start:end]\n",
    "        \n",
    "        STRESS_LABEL = 2  # passe das an, falls Stress bei dir eine andere Zahl ist (z. B. 3)\n",
    "        \n",
    "        # --- Labels binär mappen: Stress -> 2, alles andere -> 1\n",
    "        # (optional) sicherstellen, dass es ints sind:\n",
    "        label_window = label_window.astype(int, copy=False)\n",
    "        binary_window = np.where(label_window == STRESS_LABEL, 2, 1)\n",
    "        \n",
    "        # Feature-Vektor: Mittelwert + Std jeder Sensor-Spalte\n",
    "        feature_vector = np.concatenate([window.mean(axis=0), window.std(axis=0)])\n",
    "        features.append(feature_vector)\n",
    "        \n",
    "        # Mehrheits-Label (jetzt zwischen 1 = Nicht-Stress und 2 = Stress)\n",
    "        # np.bincount über Indizes 0..2; wir interessieren uns für 1 und 2\n",
    "        majority_label = np.bincount(binary_window, minlength=3)[1:].argmax() + 1\n",
    "        window_labels.append(majority_label)\n",
    "        \n",
    "        # In Arrays umwandeln\n",
    "        X = np.array(features)\n",
    "        y = np.array(window_labels)\n",
    "\n",
    "print(f\"Datensätze: {X.shape}, Klassenverteilung: {np.bincount(y)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b52959a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:46:08.444711Z",
     "iopub.status.busy": "2025-09-30T10:46:08.444375Z",
     "iopub.status.idle": "2025-09-30T10:46:08.450803Z",
     "shell.execute_reply": "2025-09-30T10:46:08.449923Z"
    },
    "papermill": {
     "duration": 0.015866,
     "end_time": "2025-09-30T10:46:08.452218",
     "exception": false,
     "start_time": "2025-09-30T10:46:08.436352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.968359  ,  33.34      , -49.9914787 , -38.16717886,\n",
       "         5.37479379])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10a235f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:46:08.469072Z",
     "iopub.status.busy": "2025-09-30T10:46:08.468724Z",
     "iopub.status.idle": "2025-09-30T10:46:52.281300Z",
     "shell.execute_reply": "2025-09-30T10:46:52.280522Z"
    },
    "papermill": {
     "duration": 43.822631,
     "end_time": "2025-09-30T10:46:52.282642",
     "exception": false,
     "start_time": "2025-09-30T10:46:08.460011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.947     1.000     0.973       143\n",
      "           2      1.000     0.467     0.636        15\n",
      "\n",
      "    accuracy                          0.949       158\n",
      "   macro avg      0.974     0.733     0.805       158\n",
      "weighted avg      0.952     0.949     0.941       158\n",
      "\n",
      "\n",
      "➡️ Bestes n_estimators: 19 mit Accuracy=0.956, F1=0.949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/random_forest_model.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modell trainieren auf 80:20 Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,     # 20% Testdaten\n",
    "    random_state=42,   # Reproduzierbarkeit\n",
    ")\n",
    "clf_testdaten = RandomForestClassifier(n_estimators=105, random_state=42)\n",
    "clf_testdaten.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Test auf 80:20 Split\n",
    "y_pred_test = clf_testdaten.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test, digits=3))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def finde_bestes_n_estimators(X_train, X_test, y_train, y_test, \n",
    "                              n_min=10, n_max=200, step=10, average=\"weighted\"):\n",
    "    ergebnisse = {}\n",
    "    \n",
    "    for n in range(n_min, n_max+1, step):\n",
    "        clf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1  = f1_score(y_test, y_pred, average=average)\n",
    "        \n",
    "        ergebnisse[n] = {\"accuracy\": acc, \"f1_score\": f1}\n",
    "        #print(f\"n_estimators={n}: Accuracy={acc:.3f}, F1={f1:.3f}\")\n",
    "    \n",
    "    # Auswahl nach bestem F1-Score\n",
    "    best_n = max(ergebnisse, key=lambda k: ergebnisse[k][\"f1_score\"])\n",
    "    best_vals = ergebnisse[best_n]\n",
    "    \n",
    "    print(f\"\\n➡️ Bestes n_estimators: {best_n} \"\n",
    "          f\"mit Accuracy={best_vals['accuracy']:.3f}, F1={best_vals['f1_score']:.3f}\")\n",
    "    \n",
    "    return best_n, ergebnisse\n",
    "\n",
    "\n",
    "finde_bestes_n_estimators(X_train, X_test, y_train, y_test, n_min=10, n_max=200, step=1)\n",
    "\n",
    "\n",
    "import joblib  # für Speichern/Laden\n",
    "\n",
    "# Modell trainieren auf kombinierten Trainingsdaten\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X, y)\n",
    "# ✅ Speichern des gesamten Modells ohne Testdatensplit\n",
    "joblib.dump(clf, \"/kaggle/working/random_forest_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99612f4",
   "metadata": {
    "papermill": {
     "duration": 0.007315,
     "end_time": "2025-09-30T10:46:52.297877",
     "exception": false,
     "start_time": "2025-09-30T10:46:52.290562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Daten der S8 ziehen und einsetzen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea9246d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:46:52.314558Z",
     "iopub.status.busy": "2025-09-30T10:46:52.314209Z",
     "iopub.status.idle": "2025-09-30T10:47:06.522266Z",
     "shell.execute_reply": "2025-09-30T10:47:06.521324Z"
    },
    "papermill": {
     "duration": 14.218277,
     "end_time": "2025-09-30T10:47:06.523769",
     "exception": false,
     "start_time": "2025-09-30T10:46:52.305492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datensätze: (17, 10), Klassenverteilung: [ 0 11  6]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 📁 Pfad zur Datei (S12)\n",
    "file_path_S12 = '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S8/S8.pkl'\n",
    "\n",
    "# 🔄 Daten laden\n",
    "with open(file_path_S12, 'rb') as f:\n",
    "    data_S12 = pd.read_pickle(f)\n",
    "\n",
    "# 📦 Zugriff auf Wrist-Signale\n",
    "wrist_S12 = data_S12['signal']['wrist']\n",
    "eda_S12 = wrist_S12['EDA']\n",
    "temp_S12 = wrist_S12['TEMP']\n",
    "acc_S12 = wrist_S12['ACC']\n",
    "\n",
    "# 🏷️ Labels (ursprünglich 700 Hz)\n",
    "labels_S12 = data_S12['label']\n",
    "\n",
    "# 🔁 Resampling der Labels auf EDA-Länge (64 Hz)\n",
    "labels_resampled_S12 = resample(labels_S12.astype(float), len(eda_S12))\n",
    "labels_resampled_S12 = np.round(labels_resampled_S12).astype(int)\n",
    "\n",
    "# 🔁 Resample ACC auf EDA-Länge\n",
    "acc_resampled_S12 = resample(acc_S12, len(eda_S12))\n",
    "\n",
    "# 🧩 Features kombinieren: EDA, TEMP, ACC → (n_samples, 6)\n",
    "X_raw_S12 = np.hstack([eda_S12, temp_S12, acc_resampled_S12])\n",
    "\n",
    "# 🪟 Sliding-Window Parameter\n",
    "window_size_S12 = 384  # 60s Fenster\n",
    "step_size_S12 = 384\n",
    "\n",
    "features_S12 = []\n",
    "window_labels_S12 = []\n",
    "\n",
    "# 🚶 Sliding-Window-Verarbeitung\n",
    "for start in range(0, len(X_raw_S12) - window_size_S12, step_size_S12):\n",
    "    end = start + window_size_S12\n",
    "    window_S12 = X_raw_S12[start:end]\n",
    "    label_window_S12 = np.round(labels_resampled_S12[start:end]).astype(int)\n",
    "\n",
    "    unique_labels_S12 = np.unique(label_window_S12)\n",
    "    \n",
    "    # ✅ Nur Fenster mit ausschließlich Label 1 oder 2\n",
    "    if set(unique_labels_S12).issubset({1, 2}):\n",
    "        majority_label_S12 = np.bincount(label_window_S12).argmax()\n",
    "        feature_vector_S12 = np.concatenate([window_S12.mean(axis=0), window_S12.std(axis=0)])\n",
    "        features_S12.append(feature_vector_S12)\n",
    "        window_labels_S12.append(majority_label_S12)\n",
    "\n",
    "# 🎯 Nur Label 1 & 2 verwenden\n",
    "mask_S12 = (np.array(window_labels_S12) == 1) | (np.array(window_labels_S12) == 2)\n",
    "X_S12 = np.array(features_S12)[mask_S12]\n",
    "y_S12 = np.array(window_labels_S12)[mask_S12]\n",
    "\n",
    "# ✅ Sicherheits-Check\n",
    "assert len(X_S12) == len(y_S12), \"Unterschiedliche Anzahl von Features und Labels!\"\n",
    "\n",
    "# ℹ️ Ergebnis anzeigen\n",
    "print(f\"Datensätze: {X_S12.shape}, Klassenverteilung: {np.bincount(y_S12)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67dac943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:47:06.540349Z",
     "iopub.status.busy": "2025-09-30T10:47:06.540017Z",
     "iopub.status.idle": "2025-09-30T10:47:06.546571Z",
     "shell.execute_reply": "2025-09-30T10:47:06.545774Z"
    },
    "papermill": {
     "duration": 0.016097,
     "end_time": "2025-09-30T10:47:06.547842",
     "exception": false,
     "start_time": "2025-09-30T10:47:06.531745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.23162565e-01,  3.34719792e+01,  3.78846147e+01,\n",
       "        -2.70410639e+01, -2.54880501e+01,  2.10455005e-02,\n",
       "         3.27592160e-02,  5.75877152e+00,  1.75788670e+01,\n",
       "         2.81943140e+01],\n",
       "       [ 4.51848799e-01,  3.35931250e+01,  3.96075191e+01,\n",
       "        -4.68303445e+01,  8.72669253e+00,  2.34686786e-02,\n",
       "         3.53792695e-02,  2.16568695e+00,  4.48472408e+00,\n",
       "         6.43844201e+00],\n",
       "       [ 3.91071099e-01,  3.36761458e+01,  3.95512693e+01,\n",
       "        -4.49509871e+01,  5.49668004e+00,  1.06702552e-02,\n",
       "         2.67266172e-02,  4.44301177e+00,  8.89256624e+00,\n",
       "         1.40801337e+01],\n",
       "       [ 3.44738273e-01,  3.37189583e+01,  4.85954461e+01,\n",
       "        -2.81452186e+01,  2.13172117e+01,  1.25650825e-02,\n",
       "         1.60714010e-02,  5.25298952e+00,  1.32988807e+01,\n",
       "         1.11939771e+01],\n",
       "       [ 3.11184562e-01,  3.37604167e+01,  5.65316527e+01,\n",
       "         3.88648454e+00,  2.42003414e+01,  6.79087833e-03,\n",
       "         2.14046659e-02,  5.99852439e+00,  5.25096019e+00,\n",
       "         1.13411289e+01],\n",
       "       [ 2.95676893e-01,  3.37879167e+01,  4.72154715e+01,\n",
       "        -3.30451942e+01, -1.88383159e+00,  6.45170964e-03,\n",
       "         1.30636795e-02,  8.24728955e+00,  2.26394212e+01,\n",
       "         6.17637084e+00],\n",
       "       [ 2.82977565e-01,  3.37725000e+01,  4.78041557e+01,\n",
       "        -2.88976712e+01,  9.95008493e+00,  7.32991403e-03,\n",
       "         1.75000000e-02,  7.72816590e+00,  1.98097987e+01,\n",
       "         1.67034020e+01],\n",
       "       [ 2.79069878e-01,  3.36941146e+01,  5.14636769e+01,\n",
       "        -8.51993742e+00, -8.43678307e+00,  8.99672019e-03,\n",
       "         3.26797497e-02,  1.04485304e+01,  2.27088074e+01,\n",
       "         2.35899363e+01],\n",
       "       [ 2.57402508e-01,  3.36514062e+01,  3.93846162e+01,\n",
       "        -4.73545873e+01, -3.79465995e+00,  3.52515184e-03,\n",
       "         1.21020643e-02,  3.91019968e+00,  5.72563603e+00,\n",
       "         8.27029043e+00],\n",
       "       [ 2.55220536e-01,  3.36253125e+01,  3.60893159e+01,\n",
       "        -4.46904458e+01, -2.24176467e+01,  3.83137899e-03,\n",
       "         1.46453295e-02,  3.89040029e+00,  4.34829227e+00,\n",
       "         1.08435268e+01],\n",
       "       [ 2.40385813e-01,  3.35827083e+01,  3.98542582e+01,\n",
       "        -4.14515705e+01, -1.94012849e+01,  5.99313803e-03,\n",
       "         2.04368523e-02,  8.95372239e+00,  4.88386485e+00,\n",
       "         1.27402867e+01],\n",
       "       [ 7.66264763e-01,  3.27348437e+01,  5.46677791e+01,\n",
       "        -3.75905961e+00,  1.32267135e+01,  4.14936388e-02,\n",
       "         1.94715755e-02,  1.22943790e+01,  1.02146158e+01,\n",
       "         2.68515413e+01],\n",
       "       [ 7.80209927e-01,  3.26514062e+01,  5.11921805e+01,\n",
       "        -2.99548421e+00,  5.76269813e+00,  5.46139692e-02,\n",
       "         2.60328631e-02,  1.38399246e+01,  2.09565291e+01,\n",
       "         2.84341548e+01],\n",
       "       [ 8.33965201e-01,  3.25254167e+01,  4.78121967e+01,\n",
       "         1.57071012e+01,  6.68884094e+00,  5.54811585e-02,\n",
       "         3.86737601e-02,  1.52177494e+01,  3.02073988e+01,\n",
       "         2.04772808e+01],\n",
       "       [ 7.73140714e-01,  3.22758333e+01,  3.22246414e+01,\n",
       "         5.45966708e+01,  2.24181613e+00,  2.42162361e-02,\n",
       "         9.48646697e-02,  1.81825298e+00,  1.16270583e+00,\n",
       "         2.20633780e+00],\n",
       "       [ 8.61951659e-01,  3.20647917e+01,  2.47984279e+01,\n",
       "         5.58690893e+01, -8.46351694e+00,  7.00658062e-02,\n",
       "         3.89705863e-02,  8.35902648e+00,  2.31500661e+00,\n",
       "         1.29483688e+01],\n",
       "       [ 7.83910219e-01,  3.20725000e+01,  1.43858455e+01,\n",
       "         5.60796642e+01, -2.63157042e+01,  2.73572624e-02,\n",
       "         2.90473751e-02,  2.35496084e+00,  1.12882982e+00,\n",
       "         2.08492731e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_S12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5847fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:47:06.564530Z",
     "iopub.status.busy": "2025-09-30T10:47:06.564200Z",
     "iopub.status.idle": "2025-09-30T10:47:06.613329Z",
     "shell.execute_reply": "2025-09-30T10:47:06.612328Z"
    },
    "papermill": {
     "duration": 0.059095,
     "end_time": "2025-09-30T10:47:06.614798",
     "exception": false,
     "start_time": "2025-09-30T10:47:06.555703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 10) (17,)\n",
      "(786, 10) (786,)\n",
      "TEST nach Laden [1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.647     1.000     0.786        11\n",
      "           2      0.000     0.000     0.000         6\n",
      "\n",
      "    accuracy                          0.647        17\n",
      "   macro avg      0.324     0.500     0.393        17\n",
      "weighted avg      0.419     0.647     0.508        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(X_S12.shape, y_S12.shape)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# ⬇️ Laden\n",
    "rf_loaded = joblib.load(\"/kaggle/working/random_forest_model.pkl\")\n",
    "\n",
    "# Testen ob es klappt\n",
    "print(\"TEST nach Laden\", rf_loaded.predict(X_S12[:5]))\n",
    "\n",
    "# Test auf Subject S12\n",
    "y_pred = clf.predict(X_S12)\n",
    "print(classification_report(y_S12, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "262d647a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:47:06.631780Z",
     "iopub.status.busy": "2025-09-30T10:47:06.631500Z",
     "iopub.status.idle": "2025-09-30T10:47:57.727793Z",
     "shell.execute_reply": "2025-09-30T10:47:57.726532Z"
    },
    "papermill": {
     "duration": 51.119644,
     "end_time": "2025-09-30T10:47:57.742456",
     "exception": false,
     "start_time": "2025-09-30T10:47:06.622812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Übersicht LOSO nur S8 (17, 10) (17,)\n",
      "Übersicht WeSad der Rest(alle) (786, 10) (786,)\n",
      "\n",
      "➡️ Bestes n_estimators: 10 mit Accuracy=0.647, F1=0.508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def finde_bestes_n_estimators(X_train, X_test, y_train, y_test, \n",
    "                              n_min=10, n_max=200, step=10, average=\"weighted\"):\n",
    "    ergebnisse = {}\n",
    "    \n",
    "    for n in range(n_min, n_max+1, step):\n",
    "        clf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1  = f1_score(y_test, y_pred, average=average)\n",
    "        \n",
    "        ergebnisse[n] = {\"accuracy\": acc, \"f1_score\": f1}\n",
    "        #print(f\"n_estimators={n}: Accuracy={acc:.3f}, F1={f1:.3f}\")\n",
    "    \n",
    "    # Auswahl nach bestem F1-Score\n",
    "    best_n = max(ergebnisse, key=lambda k: ergebnisse[k][\"f1_score\"])\n",
    "    best_vals = ergebnisse[best_n]\n",
    "    \n",
    "    print(f\"\\n➡️ Bestes n_estimators: {best_n} \"\n",
    "          f\"mit Accuracy={best_vals['accuracy']:.3f}, F1={best_vals['f1_score']:.3f}\")\n",
    "    \n",
    "    return best_n, ergebnisse\n",
    "\n",
    "print(\"Übersicht LOSO nur S8\", X_S12.shape, y_S12.shape)\n",
    "print(\"Übersicht WeSad der Rest(alle)\",X.shape, y.shape)\n",
    "\n",
    "# Setze X und Y (alle außer S8 ein) und schaue was der beste n_estimator ist\n",
    "best_estimator = finde_bestes_n_estimators(X, X_S12, y, y_S12, n_min=10, n_max=200, step=1,average=\"weighted\")\n",
    "\n",
    "# Bestes n_estimators: 27 mit Accuracy=0.941\n",
    "# Bestes n_estimators: 27 mit Accuracy=0.941, F1=0.940"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a1827",
   "metadata": {
    "papermill": {
     "duration": 0.007974,
     "end_time": "2025-09-30T10:47:57.758655",
     "exception": false,
     "start_time": "2025-09-30T10:47:57.750681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Alternative zu Random Forest testen\n",
    "\n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e440edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:47:57.776216Z",
     "iopub.status.busy": "2025-09-30T10:47:57.775851Z",
     "iopub.status.idle": "2025-09-30T10:48:02.851968Z",
     "shell.execute_reply": "2025-09-30T10:48:02.850930Z"
    },
    "papermill": {
     "duration": 5.088044,
     "end_time": "2025-09-30T10:48:02.854515",
     "exception": false,
     "start_time": "2025-09-30T10:47:57.766471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install xgboost --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ab5312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:48:02.873405Z",
     "iopub.status.busy": "2025-09-30T10:48:02.873051Z",
     "iopub.status.idle": "2025-09-30T10:48:03.510321Z",
     "shell.execute_reply": "2025-09-30T10:48:03.509593Z"
    },
    "papermill": {
     "duration": 0.648988,
     "end_time": "2025-09-30T10:48:03.511927",
     "exception": false,
     "start_time": "2025-09-30T10:48:02.862939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.647     1.000     0.786        11\n",
      "           1      0.000     0.000     0.000         6\n",
      "\n",
      "    accuracy                          0.647        17\n",
      "   macro avg      0.324     0.500     0.393        17\n",
      "weighted avg      0.419     0.647     0.508        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Filter: Nur Labels 1 (entspannt) & 2 (gestresst)\n",
    "mask_train = (y == 1) | (y == 2)\n",
    "mask_test = (y_S12 == 1) | (y_S12 == 2)\n",
    "\n",
    "X_train_filtered = X[mask_train]\n",
    "y_train_filtered = y[mask_train]\n",
    "\n",
    "X_test_filtered = X_S12[mask_test]\n",
    "y_test_filtered = y_S12[mask_test]\n",
    "\n",
    "\n",
    "# Optional: Konvertiere in DMatrix (XGBoost-eigenes Format) – ist aber nicht zwingend\n",
    "# dtrain = xgb.DMatrix(X, label=y)\n",
    "# dtest = xgb.DMatrix(X_S12, label=y_S12)\n",
    "\n",
    "# Mapping: 1 → 0 (Entspannt), 2 → 1 (Stress)\n",
    "y_train_remap = (y_train_filtered - 1).astype(int)\n",
    "y_test_remap = (y_test_filtered - 1).astype(int)\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',  # da nur 2 Klassen nach dem Mapping\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.27,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train_filtered, y_train_remap)\n",
    "y_pred = xgb_clf.predict(X_test_filtered)\n",
    "\n",
    "# Evaluation wieder mit Original-Labels:\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_remap, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5605230b",
   "metadata": {
    "papermill": {
     "duration": 0.008007,
     "end_time": "2025-09-30T10:48:03.528990",
     "exception": false,
     "start_time": "2025-09-30T10:48:03.520983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "-> Gutes Ergebnis:\n",
    "Alle Personen außer S8; sonst alle drin:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0      0.909     0.909     0.909        11\n",
    "           1      0.833     0.833     0.833         6\n",
    "\n",
    "    accuracy                          0.882        17\n",
    "   macro avg      0.871     0.871     0.871        17\n",
    "weighted avg      0.882     0.882     0.882        17\n",
    "\n",
    "-> 5/6 Stressfälle erkannt. \n",
    "Lernrate manuell angepasst -> Automatisiert noch besser.\n",
    "\n",
    "-> Interpretation: XGBoost besser als Random Forest, da Gradiant Boosting: Fehler aus vorherigen Bäumen finden + sich verbessern.\n",
    "\n",
    "Es kann auch komplexere Zusammenhänge modellieren, wo Random Forest eher Mittelwerte bildet.\n",
    "\n",
    "Boosting ist oft besser für kleine, saubere Zeitfenster-Daten als vorher.\n",
    "\n",
    "Settings:\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',  # da nur 2 Klassen nach dem Mapping\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.27,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f7aca",
   "metadata": {
    "papermill": {
     "duration": 0.007943,
     "end_time": "2025-09-30T10:48:03.545200",
     "exception": false,
     "start_time": "2025-09-30T10:48:03.537257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modell speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1ee515d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:48:03.562562Z",
     "iopub.status.busy": "2025-09-30T10:48:03.562194Z",
     "iopub.status.idle": "2025-09-30T10:48:03.566108Z",
     "shell.execute_reply": "2025-09-30T10:48:03.565430Z"
    },
    "papermill": {
     "duration": 0.013956,
     "end_time": "2025-09-30T10:48:03.567290",
     "exception": false,
     "start_time": "2025-09-30T10:48:03.553334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import joblib\n",
    "\n",
    "# Modell speichern\n",
    "#joblib.dump(xgb_clf, \"/kaggle/working/xgb_stress_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cae59e",
   "metadata": {
    "papermill": {
     "duration": 0.007897,
     "end_time": "2025-09-30T10:48:03.583418",
     "exception": false,
     "start_time": "2025-09-30T10:48:03.575521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Herausfinden, welche Parameter am besten geeignet sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abebba95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:48:03.601595Z",
     "iopub.status.busy": "2025-09-30T10:48:03.601249Z",
     "iopub.status.idle": "2025-09-30T10:48:03.608504Z",
     "shell.execute_reply": "2025-09-30T10:48:03.607605Z"
    },
    "papermill": {
     "duration": 0.017843,
     "end_time": "2025-09-30T10:48:03.609910",
     "exception": false,
     "start_time": "2025-09-30T10:48:03.592067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def finde_beste_xgb_parameter(X_train, X_test, y_train, y_test, param_grid, average=\"weighted\"):\n",
    "    ergebnisse = []\n",
    "    \n",
    "    for params in ParameterGrid(param_grid):\n",
    "        clf = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='auc',\n",
    "            random_state=42,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1  = f1_score(y_test, y_pred, average=average)\n",
    "        \n",
    "        ergebnisse.append((params, acc, f1))\n",
    "        #print(f\"Params={params} | Accuracy={acc:.3f}, F1={f1:.3f}\")\n",
    "    \n",
    "    # Sortierung nach F1, dann Accuracy\n",
    "    best_params, best_acc, best_f1 = max(ergebnisse, key=lambda x: (x[2], x[1]))\n",
    "    \n",
    "    print(f\"\\n➡️ Beste Parameter: {best_params}\")\n",
    "    print(f\"   Accuracy={best_acc:.3f}, F1={best_f1:.3f}\")\n",
    "    \n",
    "    return best_params, best_acc, best_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9780b1c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T10:48:03.628311Z",
     "iopub.status.busy": "2025-09-30T10:48:03.627554Z",
     "iopub.status.idle": "2025-09-30T11:04:54.597328Z",
     "shell.execute_reply": "2025-09-30T11:04:54.596464Z"
    },
    "papermill": {
     "duration": 1010.988973,
     "end_time": "2025-09-30T11:04:54.607275",
     "exception": false,
     "start_time": "2025-09-30T10:48:03.618302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter mit 80 20\n",
      "\n",
      "➡️ Beste Parameter: {'colsample_bytree': 0.6, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 225, 'subsample': 1.0}\n",
      "   Accuracy=0.968, F1=0.965\n"
     ]
    }
   ],
   "source": [
    "X_train_filtered = X[mask_train]\n",
    "y_train_filtered = y[mask_train]\n",
    "\n",
    "X_train_filtered = (X_train_filtered - 1).astype(int)\n",
    "y_train_filtered = (y_train_filtered - 1).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_filtered, y_train_filtered, \n",
    "    test_size=0.2,     # 20% Testdaten\n",
    "    random_state=42,   # Reproduzierbarkeit\n",
    ")\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 20, 30, 40, 50, 60,70, 80, 100, 150,175, 200,225, 250, 300],\n",
    "    \"max_depth\": [3, 5, 7, 9, 11, 13, 15],\n",
    "    \"learning_rate\": [0.05, 0.1,0.15,0.2, 0.25, 0.30],\n",
    "    \"subsample\": [0.6,0.7,0.8,0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7,0.75, 0.8,0.9,1.0]\n",
    "}\n",
    "\n",
    "print(\"Beste Parameter mit 80 20\")\n",
    "beste_params, beste_acc, beste_f1 = finde_beste_xgb_parameter(\n",
    "    X_train, X_test, y_train, y_test, param_grid\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "489d4d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:04:54.628188Z",
     "iopub.status.busy": "2025-09-30T11:04:54.627757Z",
     "iopub.status.idle": "2025-09-30T11:04:54.636758Z",
     "shell.execute_reply": "2025-09-30T11:04:54.635893Z"
    },
    "papermill": {
     "duration": 0.020229,
     "end_time": "2025-09-30T11:04:54.638156",
     "exception": false,
     "start_time": "2025-09-30T11:04:54.617927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/opt_xgb_stress_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_optimmized = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',  # da nur 2 Klassen nach dem Mapping\n",
    "    n_estimators=150,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.25,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=0.7,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    random_state=42\n",
    ")\n",
    "joblib.dump(xgb_clf_optimmized, \"/kaggle/working/opt_xgb_stress_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418d43f",
   "metadata": {
    "papermill": {
     "duration": 0.008202,
     "end_time": "2025-09-30T11:04:54.654945",
     "exception": false,
     "start_time": "2025-09-30T11:04:54.646743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testen mit S8 als LOSO Verfahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c12e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:04:54.673548Z",
     "iopub.status.busy": "2025-09-30T11:04:54.672908Z",
     "iopub.status.idle": "2025-09-30T11:21:43.043229Z",
     "shell.execute_reply": "2025-09-30T11:21:43.041876Z"
    },
    "papermill": {
     "duration": 1008.39291,
     "end_time": "2025-09-30T11:21:43.056204",
     "exception": false,
     "start_time": "2025-09-30T11:04:54.663294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter mit LOSO\n",
      "\n",
      "➡️ Beste Parameter: {'colsample_bytree': 0.6, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 225, 'subsample': 1.0}\n",
      "   Accuracy=0.968, F1=0.965\n"
     ]
    }
   ],
   "source": [
    "X_test = X_S12[mask_test]\n",
    "y_test = y_S12[mask_test]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_filtered, y_train_filtered, \n",
    "    test_size=0.2,     # 20% Testdaten\n",
    "    random_state=42,   # Reproduzierbarkeit\n",
    ")\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 20, 30, 40, 50, 60,70, 80, 100, 150,175, 200,225, 250, 300],\n",
    "    \"max_depth\": [3, 5, 7, 9, 11, 13, 15],\n",
    "    \"learning_rate\": [0.05, 0.1,0.15,0.2, 0.25, 0.30],\n",
    "    \"subsample\": [0.6,0.7,0.8,0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7,0.75, 0.8,0.9,1.0]\n",
    "}\n",
    "print(\"Beste Parameter mit LOSO\")\n",
    "\n",
    "beste_params, beste_acc, beste_f1 = finde_beste_xgb_parameter(\n",
    "    X_train, X_test, y_train, y_test, param_grid\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cc6d425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:21:43.076191Z",
     "iopub.status.busy": "2025-09-30T11:21:43.075145Z",
     "iopub.status.idle": "2025-09-30T11:21:43.170129Z",
     "shell.execute_reply": "2025-09-30T11:21:43.169326Z"
    },
    "papermill": {
     "duration": 0.108338,
     "end_time": "2025-09-30T11:21:43.173415",
     "exception": false,
     "start_time": "2025-09-30T11:21:43.065077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.647     1.000     0.786        11\n",
      "           1      0.000     0.000     0.000         6\n",
      "\n",
      "    accuracy                          0.647        17\n",
      "   macro avg      0.324     0.500     0.393        17\n",
      "weighted avg      0.419     0.647     0.508        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/opt_xgb_stress_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Filter: Nur Labels 1 (entspannt) & 2 (gestresst)\n",
    "mask_train = (y == 1) | (y == 2)\n",
    "mask_test = (y_S12 == 1) | (y_S12 == 2)\n",
    "\n",
    "X_train_filtered = X[mask_train]\n",
    "y_train_filtered = y[mask_train]\n",
    "\n",
    "X_test_filtered = X_S12[mask_test]\n",
    "y_test_filtered = y_S12[mask_test]\n",
    "\n",
    "\n",
    "# Mapping: 1 → 0 (Entspannt), 2 → 1 (Stress)\n",
    "y_train_remap = (y_train_filtered - 1).astype(int)\n",
    "y_test_remap = (y_test_filtered - 1).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',  # da nur 2 Klassen nach dem Mapping\n",
    "    n_estimators=150,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.25,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=0.7,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_clf_optimmized.fit(X_train_filtered, y_train_remap)\n",
    "y_pred = xgb_clf_optimmized.predict(X_test_filtered)\n",
    "\n",
    "# Evaluation wieder mit Original-Labels:\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_remap, y_pred, digits=3))\n",
    "\n",
    "# Speichere \n",
    "\n",
    "import joblib\n",
    "\n",
    "# Modell speichern\n",
    "joblib.dump(xgb_clf, \"/kaggle/working/opt_xgb_stress_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11febed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:21:43.193155Z",
     "iopub.status.busy": "2025-09-30T11:21:43.192825Z",
     "iopub.status.idle": "2025-09-30T11:21:43.243573Z",
     "shell.execute_reply": "2025-09-30T11:21:43.242563Z"
    },
    "papermill": {
     "duration": 0.061691,
     "end_time": "2025-09-30T11:21:43.245007",
     "exception": false,
     "start_time": "2025-09-30T11:21:43.183316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786\n",
      "786\n",
      "Gespeichert: X_test_filtered__y_train_filtered.csv -> (786, 11)\n"
     ]
    }
   ],
   "source": [
    "#Abspeichern der Werte als csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Arrays sichern\n",
    "X_train_arr = np.asarray(X_train_filtered)\n",
    "print(len(X_train_arr))\n",
    "y_train_arr = np.asarray(y_train_filtered).reshape(-1)\n",
    "print(len(y_train_filtered))\n",
    "\n",
    "\n",
    "# Längen abgleichen\n",
    "n = min(X_train_arr.shape[0], y_train_arr.shape[0])\n",
    "if X_train_arr.shape[0] != y_train_arr.shape[0]:\n",
    "    print(f\"⚠️ Unterschiedliche Längen: X_test={X_test_arr.shape[0]}, y_train={y_train_arr.shape[0]} -> kürze auf n={n}\")\n",
    "\n",
    "# DataFrame bauen\n",
    "df = pd.DataFrame(X_train_arr[:n], columns=[f\"f{i}\" for i in range(X_train_arr.shape[1])])\n",
    "df[\"label\"] = np.asarray(y_train_remap).reshape(-1)\n",
    "  # alternativ: (y_train_remap[:n]) für binäre 0/1\n",
    "\n",
    "# Export\n",
    "out_path = Path(\"X_test_filtered__y_train_filtered.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Gespeichert:\", out_path, \"->\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7dea3",
   "metadata": {
    "papermill": {
     "duration": 0.008724,
     "end_time": "2025-09-30T11:21:43.263060",
     "exception": false,
     "start_time": "2025-09-30T11:21:43.254336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SVM (\"Support Vector Maschines\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3cd9c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:21:43.281912Z",
     "iopub.status.busy": "2025-09-30T11:21:43.281603Z",
     "iopub.status.idle": "2025-09-30T11:21:52.379168Z",
     "shell.execute_reply": "2025-09-30T11:21:52.378104Z"
    },
    "papermill": {
     "duration": 9.109332,
     "end_time": "2025-09-30T11:21:52.381062",
     "exception": false,
     "start_time": "2025-09-30T11:21:43.271730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.545     0.522        11\n",
      "           1      0.000     0.000     0.000         6\n",
      "\n",
      "    accuracy                          0.353        17\n",
      "   macro avg      0.250     0.273     0.261        17\n",
      "weighted avg      0.324     0.353     0.338        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "306 fits failed out of a total of 918.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "306 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py\", line 180, in fit\n",
      "    self._validate_params()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'kernel' parameter of SVC must be a str among {'sigmoid', 'poly', 'rbf', 'precomputed', 'linear'} or a callable. Got 'polynomial' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.13095238 0.07017544        nan 0.3945516  0.07017544        nan\n",
      " 0.37721612 0.07017544        nan 0.42320757 0.07017544        nan\n",
      " 0.42658628 0.07017544        nan 0.44218782 0.07017544        nan\n",
      " 0.44466937 0.07017544        nan 0.43738782 0.07017544        nan\n",
      " 0.44588745 0.07017544        nan 0.46655931 0.07017544        nan\n",
      " 0.4552997  0.07017544        nan 0.44406471 0.07017544        nan\n",
      " 0.40170733 0.07017544        nan 0.38041918 0.07017544        nan\n",
      " 0.08051802 0.07017544        nan 0.46655931 0.07017544        nan\n",
      " 0.46655931 0.07017544        nan 0.12222222 0.07017544        nan\n",
      " 0.39928392 0.07017544        nan 0.38088183 0.07017544        nan\n",
      " 0.42300195 0.07017544        nan 0.4180143  0.07017544        nan\n",
      " 0.44218782 0.07017544        nan 0.44210526 0.07017544        nan\n",
      " 0.43982684 0.07017544        nan 0.45354887 0.07017544        nan\n",
      " 0.4650144  0.07017544        nan 0.4552997  0.07017544        nan\n",
      " 0.44128941 0.07017544        nan 0.40170733 0.07017544        nan\n",
      " 0.38041918 0.07017544        nan 0.08051802 0.07017544        nan\n",
      " 0.4650144  0.07017544        nan 0.4650144  0.07017544        nan\n",
      " 0.12429379 0.07017544        nan 0.40639325 0.07017544        nan\n",
      " 0.42022932 0.07017544        nan 0.43567251 0.07017544        nan\n",
      " 0.4219498  0.07017544        nan 0.43407971 0.07017544        nan\n",
      " 0.43674226 0.07017544        nan 0.44588745 0.07017544        nan\n",
      " 0.45558044 0.07017544        nan 0.45748988 0.07017544        nan\n",
      " 0.45372843 0.07017544        nan 0.4336748  0.07017544        nan\n",
      " 0.40311891 0.07017544        nan 0.3659612  0.07017544        nan\n",
      " 0.08051802 0.07017544        nan 0.45950094 0.07017544        nan\n",
      " 0.45748988 0.07017544        nan 0.12222222 0.07017544        nan\n",
      " 0.40639325 0.07017544        nan 0.41763192 0.07017544        nan\n",
      " 0.43495907 0.07017544        nan 0.4241698  0.07017544        nan\n",
      " 0.43918129 0.07017544        nan 0.43446384 0.07017544        nan\n",
      " 0.44131054 0.07017544        nan 0.45093795 0.07017544        nan\n",
      " 0.45016387 0.07017544        nan 0.44973545 0.07017544        nan\n",
      " 0.43503852 0.07017544        nan 0.40311891 0.07017544        nan\n",
      " 0.3672599  0.07017544        nan 0.08051802 0.07017544        nan\n",
      " 0.44534577 0.07017544        nan 0.45016387 0.07017544        nan\n",
      " 0.14204545 0.07017544        nan 0.40340005 0.07017544        nan\n",
      " 0.41546742 0.07017544        nan 0.4219498  0.07017544        nan\n",
      " 0.4241698  0.07017544        nan 0.43918129 0.07017544        nan\n",
      " 0.43224384 0.07017544        nan 0.45108201 0.07017544        nan\n",
      " 0.45285327 0.07017544        nan 0.44361416 0.07017544        nan\n",
      " 0.44827346 0.07017544        nan 0.43503852 0.07017544        nan\n",
      " 0.40311891 0.07017544        nan 0.36470807 0.07017544        nan\n",
      " 0.08051802 0.07017544        nan 0.44361416 0.07017544        nan\n",
      " 0.44361416 0.07017544        nan 0.14391026 0.07017544        nan\n",
      " 0.39817681 0.07017544        nan 0.41335841 0.07017544        nan\n",
      " 0.43052179 0.07017544        nan 0.43442381 0.07017544        nan\n",
      " 0.43220454 0.07017544        nan 0.43905611 0.07017544        nan\n",
      " 0.45330202 0.07017544        nan 0.4452478  0.07017544        nan\n",
      " 0.44033009 0.07017544        nan 0.44064242 0.07017544        nan\n",
      " 0.43503852 0.07017544        nan 0.40311891 0.07017544        nan\n",
      " 0.36470807 0.07017544        nan 0.08051802 0.07017544        nan\n",
      " 0.44033009 0.07017544        nan 0.44033009 0.07017544        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 🔄 Nur Labels 1 und 2 (wie bei XGBoost)\n",
    "mask_train = (y == 1) | (y == 2)\n",
    "mask_test = (y_S12 == 1) | (y_S12 == 2)\n",
    "\n",
    "X_train_filtered = X[mask_train]\n",
    "y_train_filtered = y[mask_train]\n",
    "X_test_filtered = X_S12[mask_test]\n",
    "y_test_filtered = y_S12[mask_test]\n",
    "\n",
    "# 🔄 Labels ummappen: 1 → 0, 2 → 1\n",
    "y_train_remap = (y_train_filtered - 1).astype(int)\n",
    "y_test_remap = (y_test_filtered - 1).astype(int)\n",
    "\n",
    "# 🔄 Features skalieren (wichtig für SVM!)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_filtered)\n",
    "X_test_scaled = scaler.transform(X_test_filtered)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [10,11,12,13,14,15],\n",
    "    'gamma': [0.01,0.02, 0.03, 0.04, 0.05,0.06, 0.07, 0.08,0.09, 0.1,0.15,0.2,0.3,0.4, 1, 'scale', 'auto'],\n",
    "    'kernel': ['rbf','linear','polynomial']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=3, scoring='f1')\n",
    "grid.fit(X_train_scaled, y_train_remap)\n",
    "\n",
    "print(\"Beste Parameter:\", grid.best_params_)\n",
    "print(\"\")\n",
    "\n",
    "# ✅ SVM mit RBF-Kernel\n",
    "svm_clf = SVC(kernel='rbf', C=10, gamma=0.1, random_state=42)\n",
    "svm_clf.fit(X_train_scaled, y_train_remap)\n",
    "\n",
    "# 🧪 Vorhersage & Bewertung\n",
    "y_pred = svm_clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test_remap, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e35eefc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:21:52.401178Z",
     "iopub.status.busy": "2025-09-30T11:21:52.400294Z",
     "iopub.status.idle": "2025-09-30T11:21:52.421088Z",
     "shell.execute_reply": "2025-09-30T11:21:52.420112Z"
    },
    "papermill": {
     "duration": 0.032355,
     "end_time": "2025-09-30T11:21:52.422708",
     "exception": false,
     "start_time": "2025-09-30T11:21:52.390353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, make_scorer\n",
    "\n",
    "def optimiere_svm(X_train, y_train, cv_splits=5, class_imbalance=True):\n",
    "    \"\"\"\n",
    "    Sucht SVM-Hyperparameter mit CV, optimiert primär F1 (weighted),\n",
    "    nutzt Accuracy als Tie-Breaker und gibt bestes Modell + Ergebnisse zurück.\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(probability=True, class_weight=\"balanced\" if class_imbalance else None))\n",
    "    ])\n",
    "\n",
    "    zwischenwerte = [round(x, 2) for x in np.arange(5, 6.01, 0.01)]\n",
    "    svc_gamma_2 = [round(x, 2) for x in np.arange(0.1, 0.2, 0.001)]\n",
    "    svc_gamma_2.extend([\"scale\", \"auto\"])\n",
    "\n",
    "    \n",
    "    param_grid = [\n",
    "        {\"svc__kernel\": [\"rbf\"],\n",
    "         \"svc__C\" :zwischenwerte,\n",
    "         #\"svc__C\": [0.1, 1, 3,5,5.5, 5.8, 6,6.5, 6.7, 7,7.5, 8, 9, 10,11,13],\n",
    "         # \"svc__gamma\": [\"scale\", \"auto\", 0.01, 0.03,0.04,0.06,0.08,0.09, 0.1, 0.11, 0.12,0.13]},\n",
    "         \"svc__gamma\": svc_gamma_2,\n",
    "        },\n",
    "        {\"svc__kernel\": [\"linear\"],\n",
    "         \"svc__C\": [0.1, 0.01, 0.03,0.04,0.06,0.08,0.09, 0.1, 0.11, 0.12,0.13, 1, 3, 10]},                 # gamma wird ignoriert\n",
    "        {\"svc__kernel\": [\"poly\"],\n",
    "         \"svc__degree\": [2, 3],\n",
    "         \"svc__coef0\": [0.0, 0.5, 1.0],\n",
    "         \"svc__C\": [0.1, 1, 3, 10],\n",
    "         \"svc__gamma\": [\"scale\", \"auto\", 0.01, 0.03,0.04,0.06,0.08,0.09, 0.1, 0.11, 0.12,0.13]},\n",
    "    ]\n",
    "\n",
    "    # Mehrere Metriken loggen; refit = F1 (weighted)\n",
    "    scorers = {\n",
    "        \"f1\": \"f1_weighted\",\n",
    "        \"accuracy\": \"accuracy\"\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    grid = GridSearchCV(pipe, param_grid, scoring=scorers, refit=\"f1\",\n",
    "                        cv=cv, n_jobs=-1, verbose=0, return_train_score=False)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Zusätzlich: Bei gleichem F1 bestes Accuracy-Modell wählen (Tie-Breaker)\n",
    "    results = grid.cv_results_\n",
    "    mean_f1 = results[\"mean_test_f1\"]\n",
    "    mean_acc = results[\"mean_test_accuracy\"]\n",
    "    best_f1 = mean_f1.max()\n",
    "    # alle Kandidaten mit maximalem F1 (numerische Toleranz)\n",
    "    idxs = [i for i, v in enumerate(mean_f1) if abs(v - best_f1) < 1e-9]\n",
    "    # wähle unter diesen die höchste Accuracy\n",
    "    best_idx = max(idxs, key=lambda i: mean_acc[i])\n",
    "\n",
    "    best_params = results[\"params\"][best_idx]\n",
    "    best_model = grid.best_estimator_ if grid.best_index_ == best_idx else Pipeline([\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    # falls Tie-Breaker anderes Set wählte, neu fitten:\n",
    "    if grid.best_index_ != best_idx:\n",
    "        best_model = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svc\", SVC(probability=True,\n",
    "                       class_weight=\"balanced\" if class_imbalance else None))\n",
    "        ])\n",
    "        best_model.set_params(**{k: v for k, v in best_params.items()})\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "    summary = {\n",
    "        \"best_params\": best_params,\n",
    "        \"cv_mean_f1\": mean_f1[best_idx],\n",
    "        \"cv_mean_accuracy\": mean_acc[best_idx]\n",
    "    }\n",
    "    return best_model, summary, grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e3e3210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:21:52.448318Z",
     "iopub.status.busy": "2025-09-30T11:21:52.447994Z",
     "iopub.status.idle": "2025-09-30T11:39:58.319845Z",
     "shell.execute_reply": "2025-09-30T11:39:58.318615Z"
    },
    "papermill": {
     "duration": 1085.897238,
     "end_time": "2025-09-30T11:39:58.331894",
     "exception": false,
     "start_time": "2025-09-30T11:21:52.434656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 5.74, 'svc__gamma': 0.2, 'svc__kernel': 'rbf'}\n",
      "CV F1=0.950, CV Acc=0.949\n"
     ]
    }
   ],
   "source": [
    "X_train_filtered = X[mask_train]\n",
    "y_train_filtered = y[mask_train]\n",
    "X_test_filtered = X_S12[mask_test]\n",
    "y_test_filtered = y_S12[mask_test]\n",
    "\n",
    "\n",
    "\n",
    "best_model, summary, grid = optimiere_svm(X_train_filtered, y_train_filtered, cv_splits=5, class_imbalance=True)\n",
    "print(summary[\"best_params\"])\n",
    "print(f\"CV F1={summary['cv_mean_f1']:.3f}, CV Acc={summary['cv_mean_accuracy']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "578ff705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:39:58.352265Z",
     "iopub.status.busy": "2025-09-30T11:39:58.351481Z",
     "iopub.status.idle": "2025-09-30T11:39:58.359287Z",
     "shell.execute_reply": "2025-09-30T11:39:58.358461Z"
    },
    "papermill": {
     "duration": 0.019673,
     "end_time": "2025-09-30T11:39:58.360695",
     "exception": false,
     "start_time": "2025-09-30T11:39:58.341022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/svm_clf_stress_model.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modell speichern\n",
    "import joblib\n",
    "\n",
    "# Modell speichern\n",
    "joblib.dump(svm_clf, \"/kaggle/working/svm_clf_stress_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac816e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T21:05:11.086668Z",
     "iopub.status.busy": "2025-08-06T21:05:11.086295Z",
     "iopub.status.idle": "2025-08-06T21:05:11.091091Z",
     "shell.execute_reply": "2025-08-06T21:05:11.090108Z",
     "shell.execute_reply.started": "2025-08-06T21:05:11.086644Z"
    },
    "papermill": {
     "duration": 0.008689,
     "end_time": "2025-09-30T11:39:58.379259",
     "exception": false,
     "start_time": "2025-09-30T11:39:58.370570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23714b3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:39:58.399609Z",
     "iopub.status.busy": "2025-09-30T11:39:58.398997Z",
     "iopub.status.idle": "2025-09-30T11:39:58.405584Z",
     "shell.execute_reply": "2025-09-30T11:39:58.404694Z"
    },
    "papermill": {
     "duration": 0.018585,
     "end_time": "2025-09-30T11:39:58.406996",
     "exception": false,
     "start_time": "2025-09-30T11:39:58.388411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def discrete_resample_by_index(labels: np.ndarray, target_len: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Mappt diskrete Labels (z.B. [0,1,2]) ohne Interpolation auf eine neue Länge.\n",
    "    Verwendet nearest/forward index mapping statt Fourier-Resampling.\n",
    "    \"\"\"\n",
    "    src_len = len(labels)\n",
    "    if src_len == target_len:\n",
    "        return labels.astype(int)\n",
    "\n",
    "    # Indizes im Quellsignal, die jeweils dem EDA-Sample am nächsten sind\n",
    "    idx = np.floor(np.linspace(0, src_len - 1, target_len)).astype(int)\n",
    "    return labels[idx].astype(int)\n",
    "\n",
    "def majority_label_in_window(win_labels: np.ndarray, valid_classes=(1,2), min_valid_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Gibt das Mehrheitslabel im Fenster zurück, wenn genug gültige Labels vorhanden sind,\n",
    "    sonst None (Fenster verwerfen).\n",
    "    \"\"\"\n",
    "    valid_mask = np.isin(win_labels, valid_classes)\n",
    "    if valid_mask.mean() < min_valid_ratio:\n",
    "        return None\n",
    "    # Nur über gültige Labels die Mehrheit bilden\n",
    "    counts = np.bincount(win_labels[valid_mask])\n",
    "    return np.argmax(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac05039e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:39:58.427827Z",
     "iopub.status.busy": "2025-09-30T11:39:58.427524Z",
     "iopub.status.idle": "2025-09-30T11:42:39.419516Z",
     "shell.execute_reply": "2025-09-30T11:42:39.418454Z"
    },
    "papermill": {
     "duration": 161.014438,
     "end_time": "2025-09-30T11:42:39.430895",
     "exception": false,
     "start_time": "2025-09-30T11:39:58.416457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datensätze: (154, 384, 5), Klassenverteilung: [154]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "file_paths = [\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S14/S14.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S13/S13.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S10/S10.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S5/S5.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S7/S7.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S9/S9.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S15/S15.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S2/S2.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S6/S6.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S3/S3.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S4/S4.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S16/S16.pkl',\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S17/S17.pkl'\n",
    "]\n",
    "\n",
    "# ChatGPT\n",
    "X_all_list = []\n",
    "y_all_list = []\n",
    "\n",
    "def zscore_subject(X):\n",
    "    mu = X.mean(axis=(0,1), keepdims=True)\n",
    "    sd = X.std(axis=(0,1), keepdims=True) + 1e-6\n",
    "    return (X - mu) / sd\n",
    "\n",
    "for file in file_paths:\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pd.read_pickle(f)\n",
    "\n",
    "    wrist = data['signal']['wrist']\n",
    "    eda = wrist['EDA']\n",
    "    temp = wrist['TEMP']\n",
    "    acc = wrist['ACC']\n",
    "    labels = data['label']\n",
    "\n",
    "    # Resample Labels auf EDA-Länge\n",
    "    #labels_resampled = resample(labels.astype(float), len(eda))\n",
    "    #labels_resampled = np.round(labels_resampled).astype(int)\n",
    "    \n",
    "    # (Optional) Nicht verwendbare Labelcodes auf 0 setzen\n",
    "    labels_clean = np.array(labels).astype(int)\n",
    "    valid_classes = {0, 1}\n",
    "    labels_clean = np.where(np.isin(labels_clean, list(valid_classes)), labels_clean, 0)\n",
    "    \n",
    "    # Diskretes Resampling ohne Mischen\n",
    "    labels_resampled = discrete_resample_by_index(labels_clean, len(eda))\n",
    "    \n",
    "    # ACC resamplen und alle Kanäle kombinieren\n",
    "    acc_resampled = resample(acc, len(eda))\n",
    "    X_raw = np.hstack([eda, temp, acc_resampled])  # shape: (n_samples, 5)\n",
    "\n",
    "    # Sliding Window\n",
    "    #window_size = 384\n",
    "    #step_size = 384\n",
    "\n",
    "    #for start in range(0, len(X_raw) - window_size, step_size):\n",
    "        #end = start + window_size\n",
    "        #window = X_raw[start:end]\n",
    "        #label_window = labels_resampled[start:end]\n",
    "\n",
    "        #if set(np.unique(label_window)).issubset({1, 2}):\n",
    "            #X_all_list.append(window)\n",
    "           # majority_label = np.bincount(label_window).argmax()\n",
    "            #y_all_list.append(majority_label)\n",
    "\n",
    "    window_size = 384\n",
    "    step_size = 384\n",
    "    \n",
    "    for start in range(0, len(X_raw) - window_size, step_size):\n",
    "        end = start + window_size\n",
    "        window = X_raw[start:end]\n",
    "        label_window = labels_resampled[start:end]\n",
    "    \n",
    "        maj = majority_label_in_window(label_window, valid_classes=(1,2), min_valid_ratio=0.8)\n",
    "        if maj is None:\n",
    "            continue  # Fenster verwerfen, zu wenig gültige Labels\n",
    "        X_all_list.append(window)\n",
    "        y_all_list.append(maj)\n",
    "\n",
    "\n",
    "X_all = [zscore_subject(X) for X in X_all_list]  # Liste aller Subjekt-Daten\n",
    "\n",
    "# In Arrays umwandeln\n",
    "X_all = np.array(X_all_list, dtype=np.float32)          # shape: (n_windows_total, 384, 5)\n",
    "y_all = (np.array(y_all_list, dtype=np.int64) - 1)      # [1,2] -> [0,1]\n",
    "\n",
    "\n",
    "print(f\"Datensätze: {X_all.shape}, Klassenverteilung: {np.bincount(y_all)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66ff0a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:42:39.451794Z",
     "iopub.status.busy": "2025-09-30T11:42:39.451369Z",
     "iopub.status.idle": "2025-09-30T11:42:39.478476Z",
     "shell.execute_reply": "2025-09-30T11:42:39.477525Z"
    },
    "papermill": {
     "duration": 0.039571,
     "end_time": "2025-09-30T11:42:39.479923",
     "exception": false,
     "start_time": "2025-09-30T11:42:39.440352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y_cnn = (y_all - 1).astype(int)  # [1, 2] → [0, 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, stratify=y_all, random_state=42\n",
    ")\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1be37f26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:42:39.499982Z",
     "iopub.status.busy": "2025-09-30T11:42:39.499676Z",
     "iopub.status.idle": "2025-09-30T11:42:55.686967Z",
     "shell.execute_reply": "2025-09-30T11:42:55.686180Z"
    },
    "papermill": {
     "duration": 16.198825,
     "end_time": "2025-09-30T11:42:55.688374",
     "exception": false,
     "start_time": "2025-09-30T11:42:39.489549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 11:42:41.283827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759232561.496908      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759232561.560742      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-09-30 11:42:55.568603: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">379</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m379\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m189\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,425</span> (44.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,425\u001b[0m (44.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,425</span> (44.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,425\u001b[0m (44.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=6, activation='relu', input_shape=(384, 5)),\n",
    "    #layers.Conv1D(32, kernel_size=2, activation='relu', input_shape=(384, 5)),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    #layers.Flatten(),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')  # binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bfca2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:42:55.710800Z",
     "iopub.status.busy": "2025-09-30T11:42:55.710201Z",
     "iopub.status.idle": "2025-09-30T11:43:01.864430Z",
     "shell.execute_reply": "2025-09-30T11:43:01.863359Z"
    },
    "papermill": {
     "duration": 6.16712,
     "end_time": "2025-09-30T11:43:01.866017",
     "exception": false,
     "start_time": "2025-09-30T11:42:55.698897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 341ms/step - accuracy: 0.4101 - auc: 0.0000e+00 - loss: 3.3353 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.7600 - val_auc: 0.0000e+00 - val_loss: 0.9308 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7923 - auc: 0.0000e+00 - loss: 1.0260 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0644 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9442 - auc: 0.0000e+00 - loss: 0.2487 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9628 - auc: 0.0000e+00 - loss: 0.0655 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 1.5799e-04 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9907 - auc: 0.0000e+00 - loss: 0.0141 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 3.8542e-05 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 8.0837e-04 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 1.5945e-05 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0061 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 9.1554e-06 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 2.9253e-04 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 7.0807e-04 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 6.2301e-06 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 7.9989e-04 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 5.4322e-06 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.5000e-04\n",
      "Beste Epoche nach F1:  1  | val_f1=0.0000\n",
      "Beste Epoche nach Acc: 2 | val_accuracy=1.0000\n",
      "Beste Epoche nach AUC: 1 | val_auc=0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# WICHTIG: AUC/Precision/Recall als Metriken loggen (für Callbacks + F1)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(3e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"best.keras\", monitor=\"val_auc\", mode=\"max\", save_best_only=True),\n",
    "    EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=8, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Chat GPT Input\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    class_weight=class_weights, \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Beste Epochen ermitteln (aus der EINEN History) ---\n",
    "hist = history.history\n",
    "val_acc = np.array(hist[\"val_accuracy\"])\n",
    "val_prec = np.array(hist[\"val_precision\"])\n",
    "val_rec  = np.array(hist[\"val_recall\"])\n",
    "val_auc  = np.array(hist[\"val_auc\"])\n",
    "\n",
    "# F1 aus Precision/Recall\n",
    "val_f1 = 2 * val_prec * val_rec / (val_prec + val_rec + 1e-7)\n",
    "\n",
    "best_epoch_f1  = int(np.argmax(val_f1)) + 1\n",
    "best_epoch_acc = int(np.argmax(val_acc)) + 1\n",
    "best_epoch_auc = int(np.argmax(val_auc)) + 1\n",
    "\n",
    "print(f\"Beste Epoche nach F1:  {best_epoch_f1}  | val_f1={val_f1[best_epoch_f1-1]:.4f}\")\n",
    "print(f\"Beste Epoche nach Acc: {best_epoch_acc} | val_accuracy={val_acc[best_epoch_acc-1]:.4f}\")\n",
    "print(f\"Beste Epoche nach AUC: {best_epoch_auc} | val_auc={val_auc[best_epoch_auc-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4febd475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:43:01.890789Z",
     "iopub.status.busy": "2025-09-30T11:43:01.890485Z",
     "iopub.status.idle": "2025-09-30T11:43:01.954898Z",
     "shell.execute_reply": "2025-09-30T11:43:01.954124Z"
    },
    "papermill": {
     "duration": 0.07861,
     "end_time": "2025-09-30T11:43:01.956526",
     "exception": false,
     "start_time": "2025-09-30T11:43:01.877916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"/kaggle/working/cnn_model.keras\")\n",
    "model.save(\"/kaggle/working/cnn_model.h5\", save_format=\"h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8265d6ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:43:01.980835Z",
     "iopub.status.busy": "2025-09-30T11:43:01.980501Z",
     "iopub.status.idle": "2025-09-30T11:43:02.309337Z",
     "shell.execute_reply": "2025-09-30T11:43:02.308367Z"
    },
    "papermill": {
     "duration": 0.34263,
     "end_time": "2025-09-30T11:43:02.310890",
     "exception": false,
     "start_time": "2025-09-30T11:43:01.968260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "[[0.00790432]\n",
      " [0.919733  ]\n",
      " [0.02802905]\n",
      " [0.02029886]\n",
      " [0.04023023]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Laden (egal ob .keras oder .h5)\n",
    "cnn_loaded = load_model(\"/kaggle/working/cnn_model.keras\")\n",
    "\n",
    "# Test\n",
    "print(cnn_loaded.predict(X_test[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7440503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:43:02.335533Z",
     "iopub.status.busy": "2025-09-30T11:43:02.335150Z",
     "iopub.status.idle": "2025-09-30T11:43:02.341323Z",
     "shell.execute_reply": "2025-09-30T11:43:02.340347Z"
    },
    "papermill": {
     "duration": 0.020112,
     "end_time": "2025-09-30T11:43:02.342790",
     "exception": false,
     "start_time": "2025-09-30T11:43:02.322678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/svm_clf_stress_model.pkl' target='_blank'>/kaggle/working/svm_clf_stress_model.pkl</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/svm_clf_stress_model.pkl"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download der Daten\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('/kaggle/working/cnn_model.keras')\n",
    "FileLink('/kaggle/working/svm_clf_stress_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8540ab77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:43:02.367812Z",
     "iopub.status.busy": "2025-09-30T11:43:02.367479Z",
     "iopub.status.idle": "2025-09-30T11:43:02.393205Z",
     "shell.execute_reply": "2025-09-30T11:43:02.392088Z"
    },
    "papermill": {
     "duration": 0.039927,
     "end_time": "2025-09-30T11:43:02.394668",
     "exception": false,
     "start_time": "2025-09-30T11:43:02.354741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Dateien vorhanden.\n",
      "models.zip: 863.1 KB\n",
      "cnn_model.h5: 173.3 KB\n",
      "random_forest_model.pkl: 671.6 KB\n",
      "svm_clf_stress_model.pkl: 18.0 KB\n",
      "cnn_model.keras: 173.2 KB\n",
      "__notebook__.ipynb: 114.5 KB\n",
      "best.keras: 173.2 KB\n",
      "X_test_filtered__y_train_filtered.csv: 147.4 KB\n",
      "opt_xgb_stress_model.pkl: 0.8 KB\n",
      "\n",
      "FERTIG: models.zip liegt in /kaggle/working und erscheint im Output-Tab.\n"
     ]
    }
   ],
   "source": [
    "import os, zipfile, shutil\n",
    "\n",
    "# 1) Sicherstellen, dass die Modelle da sind\n",
    "files_to_zip = [\n",
    "    \"/kaggle/working/cnn_model.keras\",\n",
    "    \"/kaggle/working/random_forest_model.pkl\",\n",
    "    \"/kaggle/working/svm_clf_stress_model.pkl\",\n",
    "]\n",
    "\n",
    "missing = [p for p in files_to_zip if not os.path.exists(p)]\n",
    "if missing:\n",
    "    print(\"Fehlende Dateien:\", missing)\n",
    "else:\n",
    "    print(\"Alle Dateien vorhanden.\")\n",
    "\n",
    "# 2) Sauberen Export-Ordner anlegen\n",
    "export_dir = \"/kaggle/working/export\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# 3) Dateien in den Export-Ordner kopieren (optional, hält’s übersichtlich)\n",
    "for p in files_to_zip:\n",
    "    if os.path.exists(p):\n",
    "        shutil.copy(p, os.path.join(export_dir, os.path.basename(p)))\n",
    "\n",
    "# 4) Zip nur mit diesen Dateien bauen\n",
    "zip_path = \"/kaggle/working/models.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\") as zf:\n",
    "    for name in os.listdir(export_dir):\n",
    "        zf.write(os.path.join(export_dir, name), arcname=name)\n",
    "\n",
    "# 5) Kontrolle: auflisten und Größen anzeigen\n",
    "for name in os.listdir(\"/kaggle/working\"):\n",
    "    full = os.path.join(\"/kaggle/working\", name)\n",
    "    if os.path.isfile(full):\n",
    "        print(f\"{name}: {os.path.getsize(full)/1024:.1f} KB\")\n",
    "\n",
    "print(\"\\nFERTIG: models.zip liegt in /kaggle/working und erscheint im Output-Tab.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7272ba35",
   "metadata": {
    "papermill": {
     "duration": 0.011792,
     "end_time": "2025-09-30T11:43:02.418693",
     "exception": false,
     "start_time": "2025-09-30T11:43:02.406901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ausprobieren CNN für \"gelernte Daten\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0f48266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:43:02.451299Z",
     "iopub.status.busy": "2025-09-30T11:43:02.450416Z",
     "iopub.status.idle": "2025-09-30T11:43:02.784579Z",
     "shell.execute_reply": "2025-09-30T11:43:02.783463Z"
    },
    "papermill": {
     "duration": 0.353319,
     "end_time": "2025-09-30T11:43:02.786330",
     "exception": false,
     "start_time": "2025-09-30T11:43:02.433011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.871     0.931        31\n",
      "           1      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.871        31\n",
      "   macro avg      0.500     0.435     0.466        31\n",
      "weighted avg      1.000     0.871     0.931        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Laden (egal ob .keras oder .h5)\n",
    "cnn_loaded = load_model(\"/kaggle/working/cnn_model.keras\")\n",
    "\n",
    "\n",
    "y_pred_prob = cnn_loaded.predict(X_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f7ac5",
   "metadata": {
    "papermill": {
     "duration": 0.011717,
     "end_time": "2025-09-30T11:43:02.810324",
     "exception": false,
     "start_time": "2025-09-30T11:43:02.798607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ausprobieren CNN für \"NEUE Daten\" -> 8\n",
    "\n",
    "-> Variablen ändern für S12 bzw. S8 \n",
    "-> Ausführen\n",
    "-> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e34425a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:43:02.835697Z",
     "iopub.status.busy": "2025-09-30T11:43:02.834960Z",
     "iopub.status.idle": "2025-09-30T11:43:13.528779Z",
     "shell.execute_reply": "2025-09-30T11:43:13.527802Z"
    },
    "papermill": {
     "duration": 10.708031,
     "end_time": "2025-09-30T11:43:13.530133",
     "exception": false,
     "start_time": "2025-09-30T11:43:02.822102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S8: Fenster gesamt=56, behalten=19\n",
      "Datensätze: (19, 384, 5), Klassenverteilung: [12  7]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "\n",
    "# ---------- Hilfsfunktionen ----------\n",
    "def discrete_resample_by_index(labels: np.ndarray, target_len: int) -> np.ndarray:\n",
    "    \"\"\"Diskretes 'Resampling' per Index-Mapping (keine Interpolation).\"\"\"\n",
    "    labels = np.asarray(labels).astype(np.int64)\n",
    "    src_len = len(labels)\n",
    "    if src_len == target_len:\n",
    "        return labels\n",
    "    idx = np.floor(np.linspace(0, src_len - 1, target_len)).astype(int)\n",
    "    return labels[idx]\n",
    "\n",
    "def majority_label_in_window(win_labels: np.ndarray, valid_classes=(1,2), min_valid_ratio=0.7):\n",
    "    \"\"\"Mehrheitslabel im Fenster, nur über gültige Klassen; sonst None.\"\"\"\n",
    "    vl = np.asarray(win_labels).astype(np.int64)\n",
    "    valid_mask = np.isin(vl, valid_classes)\n",
    "    if valid_mask.mean() < min_valid_ratio:\n",
    "        return None\n",
    "    counts = np.bincount(vl[valid_mask])\n",
    "    return int(np.argmax(counts))\n",
    "\n",
    "# ---------- Daten laden ----------\n",
    "file_paths = [\n",
    "    '/kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/S8/S8.pkl'\n",
    "]\n",
    "\n",
    "X_all_list_S8, y_all_list_S8 = [], []\n",
    "\n",
    "window_size = 384\n",
    "step_size   = 384\n",
    "valid_classes = (1, 2)\n",
    "\n",
    "for file in file_paths:\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pd.read_pickle(f)\n",
    "\n",
    "    wrist = data['signal']['wrist']\n",
    "    eda   = np.asarray(wrist['EDA']).reshape(-1, 1)   # (N,1)\n",
    "    temp  = np.asarray(wrist['TEMP']).reshape(-1, 1)  # (N,1)\n",
    "    acc   = np.asarray(wrist['ACC'])                  # (N,3)\n",
    "\n",
    "    labels = np.asarray(data['label']).astype(np.int64)\n",
    "\n",
    "    # 1) Labels reinigen: nur 1/2 behalten, Rest = 0 (ungültig)\n",
    "    labels_clean = np.where(np.isin(labels, valid_classes), labels, 0)\n",
    "\n",
    "    # 2) Labels diskret auf EDA-Länge mappen (kein Fourier)\n",
    "    labels_resampled = discrete_resample_by_index(labels_clean, len(eda))\n",
    "\n",
    "    # 3) ACC auf EDA-Länge bringen (hier linear/Fourier ok, da kontinuierlich)\n",
    "    acc_resampled = resample(acc, len(eda))\n",
    "\n",
    "    # 4) Feature-Matrix bauen\n",
    "    X_raw = np.hstack([eda, temp, acc_resampled])  # (N,5)\n",
    "\n",
    "    # 5) Sliding Windows + Majority Voting\n",
    "    total_windows, kept = 0, 0\n",
    "    for start in range(0, len(X_raw) - window_size, step_size):\n",
    "        end = start + window_size\n",
    "        total_windows += 1\n",
    "\n",
    "        window = X_raw[start:end]\n",
    "        label_window = labels_resampled[start:end]\n",
    "\n",
    "        maj = majority_label_in_window(label_window, valid_classes=valid_classes, min_valid_ratio=0.7)\n",
    "        if maj is None:\n",
    "            continue\n",
    "\n",
    "        X_all_list_S8.append(window)\n",
    "        y_all_list_S8.append(maj)\n",
    "        kept += 1\n",
    "\n",
    "    print(f\"S8: Fenster gesamt={total_windows}, behalten={kept}\")\n",
    "\n",
    "# 6) In Arrays umwandeln, Label-Mapping {1,2}->{0,1} genau einmal\n",
    "X_S8 = np.array(X_all_list_S8, dtype=np.float32)                 # (n_windows, 384, 5)\n",
    "y_S8 = (np.array(y_all_list_S8, dtype=np.int64) - 1).astype(int) # (n_windows,)\n",
    "\n",
    "X_S8 = zscore_subject(X_S8)\n",
    "\n",
    "print(f\"Datensätze: {X_S8.shape}, Klassenverteilung: {np.bincount(y_S8) if len(y_S8)>0 else []}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0920ff73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T11:43:13.556078Z",
     "iopub.status.busy": "2025-09-30T11:43:13.555278Z",
     "iopub.status.idle": "2025-09-30T11:43:13.949499Z",
     "shell.execute_reply": "2025-09-30T11:43:13.948307Z"
    },
    "papermill": {
     "duration": 0.408655,
     "end_time": "2025-09-30T11:43:13.951002",
     "exception": false,
     "start_time": "2025-09-30T11:43:13.542347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.222     0.167     0.190        12\n",
      "           1      0.000     0.000     0.000         7\n",
      "\n",
      "    accuracy                          0.105        19\n",
      "   macro avg      0.111     0.083     0.095        19\n",
      "weighted avg      0.140     0.105     0.120        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#y_cnn = (y_S8 - 1).astype(int)  # [1, 2] → [0, 1]\n",
    "\n",
    "#model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Laden (egal ob .keras oder .h5)\n",
    "cnn_loaded = load_model(\"/kaggle/working/cnn_model.keras\")\n",
    "\n",
    "y_pred_prob = cnn_loaded.predict(X_S8).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_S8, y_pred, digits=3))\n",
    "X_raw[8]\n",
    "\n",
    "import scipy.ndimage as nd\n",
    "p_test = cnn_loaded.predict(X_S8, verbose=0).ravel()\n",
    "p_test = nd.uniform_filter1d(p_test, size=5)   # leichte Glättung\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06242ab",
   "metadata": {
    "papermill": {
     "duration": 0.011788,
     "end_time": "2025-09-30T11:43:13.975172",
     "exception": false,
     "start_time": "2025-09-30T11:43:13.963384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7192727,
     "sourceId": 11476463,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8067774,
     "sourceId": 12762224,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8068181,
     "sourceId": 12762826,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3639.337065,
   "end_time": "2025-09-30T11:43:16.712260",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-30T10:42:37.375195",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
